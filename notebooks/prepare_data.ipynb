{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/tuyendv/Desktop/reranker/ \n",
    "from utils import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/ir/train\"\n",
    "data = load_data(path)\n",
    "data = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "train, valid = train_test_split(data, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in data:\n",
    "            json_obj = json.dumps(sample, ensure_ascii=False)\n",
    "            f.write(json_obj+\"\\n\")\n",
    "\n",
    "data_size = 50000\n",
    "n = int(len(train)/data_size)\n",
    "\n",
    "for i in range(n):\n",
    "    path = f\"data/qa_data/train/{str(i).zfill(6)}.json\"\n",
    "    save_data(path, data=train[i*data_size:(i+1)*data_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"data/qa_data/val/000000.json\", data=valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in data:\n",
    "            json_obj = json.dumps(sample, ensure_ascii=False)\n",
    "            f.write(json_obj+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tuyendv/Desktop/reranker/data/raw/squad-train-v2.0-en.json\"\n",
    "data = json.load(open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msmacro_data = []\n",
    "for text in data[\"data\"]:\n",
    "    for paragraph in text[\"paragraphs\"]:\n",
    "        passage = paragraph[\"context\"]\n",
    "        for sample in paragraph[\"qas\"]:\n",
    "            query = sample[\"question\"]\n",
    "            \n",
    "            _temp = {\n",
    "                \"query\": query,\n",
    "                \"passage\": passage\n",
    "            }\n",
    "            msmacro_data.append(_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"/home/tuyendv/Desktop/reranker/data/ir/train/squad-train-v2.0-en.json\", msmacro_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/tuyendv/Desktop/reranker\n",
    "import json\n",
    "import pandas as pd\n",
    "from bm25 import BM25\n",
    "from tqdm import tqdm\n",
    "from utils import save_data, load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tuyendv/Desktop/reranker/data/raw/squad-train-v2.0-en.json\"\n",
    "data = load_file(path)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"passage\", \"query\", \"answer\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = []\n",
    "for i, doc in enumerate(df.passage.unique().tolist()):\n",
    "    _id = str(i).zfill(6)\n",
    "    _text = doc\n",
    "    \n",
    "    passages.append([_id, _text])\n",
    "    \n",
    "passages = pd.DataFrame(passages, columns=[\"id\", \"passage_text\"])\n",
    "passages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25()\n",
    "bm25.train(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index in tqdm(df.index):\n",
    "    query = df[\"query\"][index]\n",
    "    positive_passage = df[\"passage\"][index]\n",
    "    all_passage = bm25.ranking(positive_passage, top_k=8)[\"retrieval_text\"].tolist()\n",
    "    \n",
    "    passages = []\n",
    "    mark = 0\n",
    "    for passage in all_passage:\n",
    "        if positive_passage == passage:\n",
    "            sample = {\n",
    "                \"is_selected\":1,\n",
    "                \"passage_text\":passage\n",
    "            }\n",
    "            mark = 1\n",
    "        else:\n",
    "            sample = {\n",
    "                \"is_selected\":0,\n",
    "                \"passage_text\":passage\n",
    "            }\n",
    "        passages.append(sample)\n",
    "        \n",
    "    if mark == 0:\n",
    "        sample = {\n",
    "            \"is_selected\":1,\n",
    "            \"passage_text\":positive_passage\n",
    "        }\n",
    "        passages.append(sample)\n",
    "    \n",
    "    data.append(\n",
    "        {\n",
    "            \"query\":query,\n",
    "            \"passages\":passages\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tuyendv/Desktop/reranker/data/ir/train/squad-train-v2.0-en.json\"\n",
    "save_data(path, data=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tuyendv/Desktop/reranker/data/raw/vi_data.json\"\n",
    "df = pd.read_json(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index in df.index:\n",
    "    query = df[\"question\"][index]\n",
    "    positive = df[\"positive_sample\"][index]\n",
    "    negative_samples = df[\"negative_samples\"][index]\n",
    "    \n",
    "    passages = []\n",
    "    \n",
    "    passages.append(\n",
    "        {\n",
    "            \"passage_text\":positive,\n",
    "            \"is_selected\":1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    for negative in negative_samples:\n",
    "        passages.append(\n",
    "            {\n",
    "                \"passage_text\":negative,\n",
    "                \"is_selected\":0\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    data.append(\n",
    "        {\n",
    "            \"query\":query,\n",
    "            \"passages\":passages\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in data:\n",
    "            json_obj = json.dumps(sample, ensure_ascii=False)\n",
    "            f.write(json_obj+\"\\n\")\n",
    "\n",
    "path=\"/home/tuyendv/Desktop/reranker/data/ir/vi_data.json\"\n",
    "save_data(path, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tuyendv/Desktop/reranker/data/ir/train/ms-macro-train_v1.1.json\"\n",
    "\n",
    "data = []\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = json.loads(line.strip())\n",
    "        passages = [\n",
    "            {\n",
    "                \"passage_text\":i[\"passage_text\"],\n",
    "                \"is_selected\":i[\"is_selected\"]\n",
    "                } for i in line[\"passages\"]\n",
    "            ]\n",
    "        data.append(\n",
    "            {\n",
    "                \"query\":line[\"query\"],\n",
    "                \"passages\":passages\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in data:\n",
    "            json_obj = json.dumps(sample, ensure_ascii=False)\n",
    "            f.write(json_obj+\"\\n\")\n",
    "\n",
    "path = \"/home/tuyendv/Desktop/reranker/data/ir/train/ms-macro-train_v1.1.json\"\n",
    "save_data(path, data[0:30000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/tuyendv/Desktop/reranker/\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import load_file, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/tuyendv/Desktop/reranker/data/processed-ir-data/train'\n",
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(query, passages):\n",
    "    query_length = len(query.split())\n",
    "    \n",
    "    lengths = []\n",
    "    for pa in passages:\n",
    "        tmp = pa[\"passage_text\"]\n",
    "        \n",
    "        lengths.append(len(tmp.split()) + query_length)\n",
    "        \n",
    "    return lengths\n",
    "\n",
    "df[\"length\"] = df.apply(lambda x: get_length(x[\"query\"], x[\"passages\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_pass\"] = df.passages.apply(lambda x: len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [i for j in df.length.tolist() for i in j]\n",
    "pd.DataFrame(lengths, columns=[\"lengths\"]).lengths.hist(bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/tuyendv/Desktop/reranker/\n",
    "import os \n",
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tuyendv/Desktop/reranker/data/ir/test\"\n",
    "data = load_data(path)\n",
    "data = [json.loads(line) for line in data]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(query, passages):\n",
    "    query_length = len(query.split())\n",
    "    \n",
    "    lengths = []\n",
    "    for pa in passages:\n",
    "        tmp = pa[\"passage_text\"]\n",
    "        \n",
    "        lengths.append(len(tmp.split()) + query_length)\n",
    "        \n",
    "    return lengths\n",
    "\n",
    "data[\"length\"] = data.apply(lambda x: get_length(x[\"query\"], x[\"passages\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [i for j in data.length.tolist() for i in j]\n",
    "pd.DataFrame(lengths, columns=[\"lengths\"]).lengths.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [i for j in data.length.tolist() for i in j]\n",
    "pd.DataFrame(lengths, columns=[\"lengths\"]).lengths.hist(bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
